清明节三天，

day1，去了雁栖湖。在怀柔区的城区往北大约10km处。有一个形状怪异的酒店，大概每晚6000元。

整个环湖有租自行车环湖的车道，不过一小时的费用在30-100元之间，简直就是抢钱。

另外景区门票费用是42rmb，没啥好玩的，游玩项目额外加钱，100RMB可以选5个项目。

另外从望京到怀柔的公交车5rmb，堵车堵到怀疑人生。

晚上吃了一条黑鱼，38一斤，3斤半。花了186.


day2，学习了hive和elasticsearch的数据相互转换的操作，考虑是不是需要建立一个elasticsearch的分布式版本，加快读取速度，不然500w条数据读取约10分钟的时间。

下载以来并放到hdfs

```bash
wget https://artifacts.elastic.co/downloads/elasticsearch-hadoop/elasticsearch-hadoop-6.3.0.zip
unzip elasticsearch-hadoop-6.3.0.zip
hdfs dfs -mkdir /user/test/es_hadoop/
hdfs dfs -put elasticsearch-hadoop-hive-6.3.0.jar /user/test/es_hadoop/
ADD JAR hdfs://test/user/test/es_hadoop/elasticsearch-hadoop-hive-6.3.0.jar;
```

hive加载jar包
```hive
add jar hdfs:///elasticsearch-jars/elasticsearch-hadoop-hive-8.1.1.jar;
```
从elasticsearch同步数据到hive
建表语句

```hive
add jar hdfs:///elasticsearch-jars/elasticsearch-hadoop-hive-8.1.1.jar;
CREATE EXTERNAL TABLE beike.ershoufang_from_es (
     details_name string,
    postition_url string ,
    house_url string,
    house_id string,
    house_info string,
    follew_info string,
    subway string,
    total_price float,
    total_price_danwei string,
    unit_price float,
    district string,
    city_name string,
    fetchtime timestamp
)
STORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler'
TBLPROPERTIES(
    'es.resource' = 'beike_ershoufang_all/doc',
    'es.nodes' = 'http://10.147.20.10',
    'es.port'='9200',
    'es.index.auto.create'='false', -- 不建立
    'es.read.metadata'='true'
    );

````

建hive数据源的表
```hive
create table beike.beike_ershoufang (
    details_name string,
    postition_url string ,
    house_url string,
    house_id string,
    house_info string,
    follew_info string,
    subway string,
    total_price float,
    total_price_danwei string,
    unit_price float,
    district string,
    city_name string,
    fetchtime timestamp
)
partitioned by (dt string)
row format delimited fields terminated by ","
LINES TERMINATED BY '\n';
```

同步数据
```hive
add jar hdfs:///elasticsearch-jars/elasticsearch-hadoop-hive-8.1.1.jar;
insert overwrite table  beike.beike_ershoufang partition (dt=20220406) select * from default.ershoufang_from_es;

```

从hive查询数据
```hive

select * from  beike.beike_ershoufang where dt='20220406' limit 100;
```


### 从hive同步数据到elasticsearch
建hive-elasticsearch关联的表
```hive
CREATE EXTERNAL TABLE index_name_to_es (
    field1 string,
    field2 int
    )
STORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler'
TBLPROPERTIES('es.resource' = 'demo/_doc',
    'es.index.auto.create' = 'true',
    'es.nodes' = 'http://10.147.20.10',
    'es.port'='9200'
);

```
往es灌数据
```hive
insert into table index_name_to_es
values ('zeng',12);
```


dwd数据建模

```hive
create table dwd_beike.beike_ershoufang (
    details_name string,
    postition_url string ,
    house_url string,
    house_id string,

    --house_info string,

    house_height string,
    house_total_height int,
    house_area float,
    house_direction string,

    --follew_info string,
    persons_fellow int,
    time_publish string,

    --subway string,
    house_feature string,

    total_price float,
    total_price_danwei string,
    unit_price float,
    district string,
    city_name string,
    fetchtime timestamp
)
partitioned by (dt string)
row format delimited fields terminated by ","
LINES TERMINATED BY '\n';
```

```hive
insert overwrite table dwd_beike.beike_ershoufang partition(dt=20220406)
select 

details_name, 
postition_url, 
house_url, 
house_id, 
spilt(split(house_info,"\\|")[0],'\\(')[0], 
spilt(split(house_info,"\\|")[0],'\\(')[1],"\\)"[0],


cast(split(split(house_info,"\\|")[1],'平米')[0] as float)
split(house_info,"\\|")[2]
--follew_info, 
split(follew_info,'\\/')[0],
split(follew_info,'\\/')[1],

subway,
 total_price, 
 total_price_danwei, 
 unit_price, 
 district, 
 city_name, 
 fetchtime

from beike.beike_ershoufang
where dt = 20220406
and postition_url is not null




```